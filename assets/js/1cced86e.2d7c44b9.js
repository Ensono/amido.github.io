"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[3830],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return f}});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),u=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},c=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},k=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=u(a),k=n,f=d["".concat(s,".").concat(k)]||d[k]||p[k]||o;return a?r.createElement(f,l(l({ref:t},c),{},{components:a})):r.createElement(f,l({ref:t},c))}));function f(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,l=new Array(o);l[0]=k;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[d]="string"==typeof e?e:n,l[1]=i;for(var u=2;u<o;u++)l[u]=a[u];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}k.displayName="MDXCreateElement"},9005:function(e,t,a){a.r(t),a.d(t,{assets:function(){return c},contentTitle:function(){return s},default:function(){return f},frontMatter:function(){return i},metadata:function(){return u},toc:function(){return d}});var r=a(7462),n=a(3366),o=(a(7294),a(3905)),l=["components"],i={id:"intro_data_azure",title:"Ensono Stacks Azure Data Platform",sidebar_label:"Introduction",hide_title:!1,hide_table_of_contents:!1,description:"Introduction to Ensono Stacks Azure Data Platform",keywords:["data","python","etl","databricks","azure","adf","template"]},s=void 0,u={unversionedId:"workloads/azure/data/intro_data_azure",id:"workloads/azure/data/intro_data_azure",title:"Ensono Stacks Azure Data Platform",description:"Introduction to Ensono Stacks Azure Data Platform",source:"@site/docs/workloads/azure/data/intro_data_azure.md",sourceDirName:"workloads/azure/data",slug:"/workloads/azure/data/intro_data_azure",permalink:"/docs/workloads/azure/data/intro_data_azure",draft:!1,tags:[],version:"current",frontMatter:{id:"intro_data_azure",title:"Ensono Stacks Azure Data Platform",sidebar_label:"Introduction",hide_title:!1,hide_table_of_contents:!1,description:"Introduction to Ensono Stacks Azure Data Platform",keywords:["data","python","etl","databricks","azure","adf","template"]},sidebar:"docs",previous:{title:"Security",permalink:"/docs/workloads/azure/backend/netcore/security_netcore"},next:{title:"Architecture Overview",permalink:"/docs/workloads/azure/data/architecture/architecture_data_azure"}},c={},d=[{value:"High-level architecture",id:"high-level-architecture",level:3},{value:"Infrastructure deployed",id:"infrastructure-deployed",level:3},{value:"Data Engineering workloads",id:"data-engineering-workloads",level:3}],p={toc:d},k="wrapper";function f(e){var t=e.components,i=(0,n.Z)(e,l);return(0,o.kt)(k,(0,r.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/ensono/stacks-azure-data"},"Ensono Stacks Azure Data Platform")," solution provides\na framework for accelerating the deployment of a production-ready data platform."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Ensono Stacks Data Overview",src:a(8821).Z,width:"1651",height:"1524"})),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Use the ",(0,o.kt)("a",{parentName:"li",href:"../../../stackscli/about"},"Ensono Stacks CLI")," to generate a new data platform project."),(0,o.kt)("li",{parentName:"ol"},"Build and deploy the data platform infrastructure into your Azure environment."),(0,o.kt)("li",{parentName:"ol"},"Accelerate development of data workloads and ETL pipelines with ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/etl_pipelines/datastacks"},"Datastacks"),".")),(0,o.kt)("p",null,"The Ensono Stacks Data Platform utilises tools including ",(0,o.kt)("strong",{parentName:"p"},"Azure Data Factory")," for data\ningestion and orchestration, ",(0,o.kt)("strong",{parentName:"p"},"Databricks")," for data processing and ",(0,o.kt)("strong",{parentName:"p"},"Azure Data Lake Storage Gen2"),"\nfor data lake storage. The solution is based around a ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/etl_pipelines/etl_intro_data_azure#medallion-architecture"},"Medallion Architecture"),", with Bronze, Silver and Gold layers for various stages of data preparation."),(0,o.kt)("p",null,"Key elements of the solution include:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Infrastructure as code (IaC) for all infrastructure components (Terraform)."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/etl_pipelines/datastacks"},"Datastacks")," - a library and CLI built to accelerate the development of data engineering\nworkloads in the data platform based upon templates."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/etl_pipelines/pysparkle"},"Pysparkle")," - a library built to streamline data processing activities running in Apache Spark."),(0,o.kt)("li",{parentName:"ul"},"Sample ingest pipeline that transfers data from a source into a landing (Bronze) data lake zone."),(0,o.kt)("li",{parentName:"ul"},"Sample data processing pipelines performing data transformations from Bronze to Silver and Silver to Gold layers."),(0,o.kt)("li",{parentName:"ul"},"Data Quality validations."),(0,o.kt)("li",{parentName:"ul"},"Deployment pipelines to enable CI/CD and DataOps for all components."),(0,o.kt)("li",{parentName:"ul"},"Automated tests to ensure quality assurance and operational efficiency.")),(0,o.kt)("h3",{id:"high-level-architecture"},"High-level architecture"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"High-level architecture",src:a(2808).Z,width:"4536",height:"2758"})),(0,o.kt)("h3",{id:"infrastructure-deployed"},"Infrastructure deployed"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Resource Group"),(0,o.kt)("li",{parentName:"ul"},"Key Vault"),(0,o.kt)("li",{parentName:"ul"},"Azure Data Lake Storage Gen2"),(0,o.kt)("li",{parentName:"ul"},"Azure Blob Storage"),(0,o.kt)("li",{parentName:"ul"},"Azure Data Factory"),(0,o.kt)("li",{parentName:"ul"},"Log Analytics Workspace"),(0,o.kt)("li",{parentName:"ul"},"Databricks Workspace (optional)"),(0,o.kt)("li",{parentName:"ul"},"Azure SQL Database (optional)")),(0,o.kt)("p",null,"The solution may be deployed within a secure private network. For details please see ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/infrastructure_data_azure"},"Infrastructure"),"."),(0,o.kt)("h3",{id:"data-engineering-workloads"},"Data Engineering workloads"),(0,o.kt)("p",null,"Example data engineering workloads are provided, based upon the Datastacks templates:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/etl_pipelines/ingest_data_azure"},"Ingest")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/etl_pipelines/data_processing"},"Bronze to Silver"))),(0,o.kt)("p",null,"Each of the ingest and data processing workloads may optionally include ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/etl_pipelines/data_quality_azure"},"Data Quality checks"),"."))}f.isMDXComponent=!0},2808:function(e,t,a){t.Z=a.p+"assets/images/Stacks_Azure_Data_Platform-HLD-46ecbcba3e69eb2fe5fd1e354960ed5f.png"},8821:function(e,t,a){t.Z=a.p+"assets/images/stacks-data-overview-a179ba5ce75d215026d7ea9eefcd0e1d.png"}}]);