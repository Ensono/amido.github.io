"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[6169],{2810:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>d,metadata:()=>a,toc:()=>o});const a=JSON.parse('{"id":"workloads/azure/data/data_engineering/datastacks","title":"Datastacks CLI","description":"Overview of the Datastacks CLI utility","source":"@site/docs/workloads/azure/data/data_engineering/datastacks.md","sourceDirName":"workloads/azure/data/data_engineering","slug":"/workloads/azure/data/data_engineering/datastacks","permalink":"/docs/workloads/azure/data/data_engineering/datastacks","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"datastacks","title":"Datastacks CLI","sidebar_label":"Datastacks CLI","hide_title":false,"hide_table_of_contents":false,"description":"Overview of the Datastacks CLI utility","keywords":["data","python","etl","cli","azure","template"]},"sidebar":"docs","previous":{"title":"Stacks Data Utilities","permalink":"/docs/workloads/azure/data/data_engineering/stacks_data_utilities"},"next":{"title":"Data Ingest Workloads","permalink":"/docs/workloads/azure/data/data_engineering/ingest_data_azure"}}');var s=n(4848),r=n(8453);const d={id:"datastacks",title:"Datastacks CLI",sidebar_label:"Datastacks CLI",hide_title:!1,hide_table_of_contents:!1,description:"Overview of the Datastacks CLI utility",keywords:["data","python","etl","cli","azure","template"]},i=void 0,l={},o=[{value:"Using the Datastacks CLI",id:"using-the-datastacks-cli",level:2},{value:"Generating data workloads",id:"generating-data-workloads",level:2},{value:"Commands",id:"commands",level:3},{value:"Examples",id:"examples",level:3},{value:"Configuration",id:"configuration",level:3},{value:"All workloads",id:"all-workloads",level:4},{value:"Ingest workloads",id:"ingest-workloads",level:4},{value:"Processing workloads",id:"processing-workloads",level:4}];function c(e){const t={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",section:"section",strong:"strong",sup:"sup",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:["The Datastacks CLI is a command-line interface for data engineers, built upon the ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/stacks_data_utilities",children:"Stacks Data Python library"}),". It's features include:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"#generating-data-workloads",children:"Data workload generation"})," - Generate new data engineering workloads based upon common templates."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/data_quality_azure#interactive-usage",children:"Data quality checks"})," - Interactively run data quality checks over a data source."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"using-the-datastacks-cli",children:"Using the Datastacks CLI"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure",children:"Setup project environment"})}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"# Option 1: Run Datastacks CLI using Poetry's interactive shell (recommended for local development)\npoetry shell\ndatastacks --help\n\n# Option 2: Run Datastacks CLI using poetry run (recommended where Poetry shell cannot be used, e.g. CI/CD pipelines)\npoetry run datastacks --help\n"})}),"\n",(0,s.jsx)(t.h2,{id:"generating-data-workloads",children:"Generating data workloads"}),"\n",(0,s.jsxs)(t.p,{children:["Datastacks can be used to generate all the resources required for a new data engineering workload - for example a ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/ingest_data_azure",children:"data ingest"})," or ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/data_processing",children:"data processing"})," pipeline. This will create all resources required for the workload, based upon templates."]}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/architecture/architecture_data_azure#deployment-workflow",children:"deployment architecture"})," section shows the workflow for using Datastacks to generate a new workload.\nThe ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/",children:"getting started"})," section includes step-by-step instructions on deploying a new ingest or processing workload using Datastacks."]}),"\n",(0,s.jsx)(t.h3,{id:"commands",children:"Commands"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"generate"})}),": Top-level command for generating resources for a new data workload."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"ingest"})}),": Subcommand to generate a new ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/ingest_data_azure",children:"data ingest workload"}),", using the provided configuration file. A optional flag (",(0,s.jsx)(t.code,{children:"--data-quality"})," or ",(0,s.jsx)(t.code,{children:"-dq"}),") can be included to specify whether to include data quality components in the workload."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"processing"})}),": Subcommand to generate a new ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/data_processing",children:"data processing workload"}),", using the provided configuration file. A optional flag (",(0,s.jsx)(t.code,{children:"--data-quality"})," or ",(0,s.jsx)(t.code,{children:"-dq"}),") can be included to specify whether to include data quality components in the workload."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:'# Activate virtual environment\npoetry shell\n\n# Generate resources for an ingest workload\ndatastacks generate ingest --config="de_workloads/generate_examples/test_config_ingest.yaml"\n\n# Generate resources for an ingest workload, with added data quality steps\ndatastacks generate ingest --config="de_workloads/generate_examples/test_config_ingest.yaml" --data-quality\n\n# Generate resources for a processing workload\ndatastacks generate processing --config="de_workloads/generate_examples/test_config_processing.yaml"\n\n# Generate resources for a processing workload, with added data quality steps\ndatastacks generate processing --config="de_workloads/generate_examples/test_config_processing.yaml" --data-quality\n'})}),"\n",(0,s.jsx)(t.h3,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(t.p,{children:["In order to generate a new data engineering workload the Datastacks CLI takes a path to a config file. This config file should be YAML format, and contain configuration values as specified in the table below. Sample config files are included in the ",(0,s.jsx)(t.a,{href:"https://github.com/ensono/stacks-azure-data/tree/main/de_workloads/generate_examples",children:"de_workloads/generate_examples"})," folder."]}),"\n",(0,s.jsx)(t.h4,{id:"all-workloads",children:"All workloads"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Config field"}),(0,s.jsx)(t.th,{children:"Description"}),(0,s.jsx)(t.th,{children:"Required?"}),(0,s.jsx)(t.th,{children:"Format"}),(0,s.jsx)(t.th,{children:"Default value"}),(0,s.jsx)(t.th,{children:"Example value"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"pipeline_description"}),(0,s.jsx)(t.td,{children:"Description of the pipeline to be created. Will be used for the Data Factory pipeline description."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:'"Ingest from demo Azure SQL database using ingest config file."'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"ado_variable_groups_nonprod"}),(0,s.jsx)(t.td,{children:"List of required variable groups in non-production environment."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"List[String]"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsxs)(t.td,{children:["- amido-stacks-de-pipeline-nonprod",(0,s.jsx)("br",{}),"- stacks-credentials-nonprod-kv"]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"ado_variable_groups_prod"}),(0,s.jsx)(t.td,{children:"List of required variable groups in production environment."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"List[String]"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsxs)(t.td,{children:["- amido-stacks-de-pipeline-prod",(0,s.jsx)("br",{}),"- stacks-credentials-prod-kv"]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"default_arm_deployment_mode"}),(0,s.jsx)(t.td,{children:"Deployment mode for terraform."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'"Incremental"'}),(0,s.jsx)(t.td,{children:"Incremental"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"stacks_data_package_version"}),(0,s.jsxs)(t.td,{children:["Version of the ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/stacks_data_utilities",children:"stacks-data"})," Python package in PyPi to install on the job cluster."]}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"String (SemVer pattern)"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"Latest available package at the time of generation"})}),(0,s.jsx)(t.td,{children:"0.1.2"})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"ingest-workloads",children:"Ingest workloads"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Config field"}),(0,s.jsx)(t.th,{children:"Description"}),(0,s.jsx)(t.th,{children:"Required?"}),(0,s.jsx)(t.th,{children:"Format"}),(0,s.jsx)(t.th,{children:"Default value"}),(0,s.jsx)(t.th,{children:"Example value"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"dataset_name"}),(0,s.jsx)(t.td,{children:"Dataset name, used to derive pipeline and linked service names, e.g. AzureSql_Example."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"azure_sql_demo"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"data_source_password_key_vault_secret_name"}),(0,s.jsx)(t.td,{children:"Secret name of the data source password in Key Vault."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"sql-password"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"data_source_connection_string_variable_name"}),(0,s.jsx)(t.td,{children:"Variable name for the connection string."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"sql_connection"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"data_source_type"}),(0,s.jsx)(t.td,{children:"Data source type."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsxs)(t.td,{children:["String",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),"Allowed values",(0,s.jsx)(t.sup,{children:(0,s.jsx)(t.a,{href:"#user-content-fn-1",id:"user-content-fnref-1","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),":",(0,s.jsx)("br",{}),'"azure_sql"']}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"azure_sql"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"bronze_container"}),(0,s.jsx)(t.td,{children:"Name of container for landing ingested data."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"raw"}),(0,s.jsx)(t.td,{children:"raw"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"key_vault_linked_service_name"}),(0,s.jsx)(t.td,{children:"Name of the Key Vault linked service in Data Factory."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"ls_KeyVault"}),(0,s.jsx)(t.td,{children:"ls_KeyVault"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"trigger_start"}),(0,s.jsx)(t.td,{children:"Start datetime for Data Factory pipeline trigger."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"Datetime"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"2010-01-01T00:00:00Z"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"trigger_end"}),(0,s.jsx)(t.td,{children:"Datetime to set as end time for pipeline trigger."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"Datetime"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"2011-12-31T23:59:59Z"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"trigger_frequency"}),(0,s.jsx)(t.td,{children:"Frequency for the Data Factory pipeline trigger."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsxs)(t.td,{children:["String",(0,s.jsx)("br",{}),(0,s.jsx)("br",{}),"Allowed values:",(0,s.jsx)("br",{}),'"Minute"',(0,s.jsx)("br",{}),'"Hour"',(0,s.jsx)("br",{}),'"Day"',(0,s.jsx)("br",{}),'"Week"',(0,s.jsx)("br",{}),'"Month"']}),(0,s.jsx)(t.td,{children:'"Month"'}),(0,s.jsx)(t.td,{children:"Month"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"trigger_interval"}),(0,s.jsx)(t.td,{children:"Interval value for the Data Factory pipeline trigger."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"1"}),(0,s.jsx)(t.td,{children:"1"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"trigger_delay"}),(0,s.jsxs)(t.td,{children:["Delay between Data Factory pipeline triggers, formatted HH:mm",":ss"]}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'"02:00:00"'}),(0,s.jsx)(t.td,{children:"02:00:00"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"window_start_default"}),(0,s.jsx)(t.td,{children:"Default window start date in the Data Factory pipeline."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"Date"}),(0,s.jsx)(t.td,{children:'"2010-01-01"'}),(0,s.jsx)(t.td,{children:"2010-01-01"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"window_end_default"}),(0,s.jsx)(t.td,{children:"Default window end date in the Data Factory pipeline."}),(0,s.jsx)(t.td,{children:"No"}),(0,s.jsx)(t.td,{children:"Date"}),(0,s.jsx)(t.td,{children:'"2010-01-31"'}),(0,s.jsx)(t.td,{children:"2010-01-31"})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"processing-workloads",children:"Processing workloads"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Config field"}),(0,s.jsx)(t.th,{children:"Description"}),(0,s.jsx)(t.th,{children:"Required?"}),(0,s.jsx)(t.th,{children:"Format"}),(0,s.jsx)(t.th,{children:"Default value"}),(0,s.jsx)(t.th,{children:"Example value"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"pipeline_name"}),(0,s.jsx)(t.td,{children:"Name of the data pipeline / workload."}),(0,s.jsx)(t.td,{children:"Yes"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.em,{children:"n/a"})}),(0,s.jsx)(t.td,{children:"processing_demo"})]})})]}),"\n","\n",(0,s.jsxs)(t.section,{"data-footnotes":!0,className:"footnotes",children:[(0,s.jsx)(t.h2,{className:"sr-only",id:"footnote-label",children:"Footnotes"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{id:"user-content-fn-1",children:["\n",(0,s.jsxs)(t.p,{children:["Additional data source types will be supported in future - see ",(0,s.jsx)(t.a,{href:"/docs/workloads/azure/data/data_engineering/ingest_data_azure#data-source-types",children:"ingest data source types"}),". ",(0,s.jsx)(t.a,{href:"#user-content-fnref-1","data-footnote-backref":"","aria-label":"Back to reference 1",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>d,x:()=>i});var a=n(6540);const s={},r=a.createContext(s);function d(e){const t=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),a.createElement(r.Provider,{value:t},e.children)}}}]);