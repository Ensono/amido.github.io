"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[3830],{3905:function(e,a,t){t.d(a,{Zo:function(){return u},kt:function(){return f}});var r=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);a&&(r=r.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,r,n=function(e,a){if(null==e)return{};var t,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var s=r.createContext({}),d=function(e){var a=r.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},u=function(e){var a=d(e.components);return r.createElement(s.Provider,{value:a},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var a=e.children;return r.createElement(r.Fragment,{},a)}},k=r.forwardRef((function(e,a){var t=e.components,n=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=d(t),k=n,f=c["".concat(s,".").concat(k)]||c[k]||p[k]||o;return t?r.createElement(f,i(i({ref:a},u),{},{components:t})):r.createElement(f,i({ref:a},u))}));function f(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var o=t.length,i=new Array(o);i[0]=k;var l={};for(var s in a)hasOwnProperty.call(a,s)&&(l[s]=a[s]);l.originalType=e,l[c]="string"==typeof e?e:n,i[1]=l;for(var d=2;d<o;d++)i[d]=t[d];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}k.displayName="MDXCreateElement"},9005:function(e,a,t){t.r(a),t.d(a,{assets:function(){return u},contentTitle:function(){return s},default:function(){return f},frontMatter:function(){return l},metadata:function(){return d},toc:function(){return c}});var r=t(7462),n=t(3366),o=(t(7294),t(3905)),i=["components"],l={id:"intro_data_azure",title:"Ensono Stacks Azure Data Platform",sidebar_label:"Introduction",hide_title:!1,hide_table_of_contents:!1,description:"Introduction to Ensono Stacks Azure Data Platform",keywords:["data","python","etl","databricks","azure","adf","template"]},s=void 0,d={unversionedId:"workloads/azure/data/intro_data_azure",id:"workloads/azure/data/intro_data_azure",title:"Ensono Stacks Azure Data Platform",description:"Introduction to Ensono Stacks Azure Data Platform",source:"@site/docs/workloads/azure/data/intro_data_azure.md",sourceDirName:"workloads/azure/data",slug:"/workloads/azure/data/intro_data_azure",permalink:"/docs/workloads/azure/data/intro_data_azure",draft:!1,tags:[],version:"current",frontMatter:{id:"intro_data_azure",title:"Ensono Stacks Azure Data Platform",sidebar_label:"Introduction",hide_title:!1,hide_table_of_contents:!1,description:"Introduction to Ensono Stacks Azure Data Platform",keywords:["data","python","etl","databricks","azure","adf","template"]},sidebar:"docs",previous:{title:"AWS SQS module",permalink:"/docs/workloads/aws/backend/java/architecture/dependency_sqs_java"},next:{title:"Architecture Overview",permalink:"/docs/workloads/azure/data/architecture/architecture_data_azure"}},u={},c=[{value:"High-level architecture",id:"high-level-architecture",level:3},{value:"Infrastructure deployed",id:"infrastructure-deployed",level:3},{value:"Data Engineering workloads",id:"data-engineering-workloads",level:3}],p={toc:c},k="wrapper";function f(e){var a=e.components,l=(0,n.Z)(e,i);return(0,o.kt)(k,(0,r.Z)({},p,l,{components:a,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"The ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/ensono/stacks-azure-data"},"Ensono Stacks Azure Data Platform")," solution provides\na framework for accelerating the deployment of a production-ready modern data platform in Azure."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Ensono Stacks Data Overview",src:t(8821).Z,width:"1651",height:"1524"})),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Use the ",(0,o.kt)("a",{parentName:"li",href:"/docs/stackscli/about"},"Ensono Stacks CLI")," to generate a new data platform project."),(0,o.kt)("li",{parentName:"ol"},"Build and deploy the data platform infrastructure into your Azure environment."),(0,o.kt)("li",{parentName:"ol"},"Accelerate development of data workloads and ELT pipelines with the ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/datastacks"},"Datastacks CLI"),".")),(0,o.kt)("p",null,"The Ensono Stacks Data Platform delivers a modern ",(0,o.kt)("em",{parentName:"p"},"Lakehouse")," solution, based upon the ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/data_engineering/data_engineering_intro_azure#medallion-architecture"},"medallion architecture"),", with Bronze, Silver and Gold layers for various stages of data preparation. The platform utilises tools including ",(0,o.kt)("strong",{parentName:"p"},"Azure Data Factory")," for data ingestion and orchestration, ",(0,o.kt)("strong",{parentName:"p"},"Databricks")," for data processing and ",(0,o.kt)("strong",{parentName:"p"},"Azure Data Lake Storage Gen2")," for data lake storage. It provides a foundation for data analytics and reporting through ",(0,o.kt)("strong",{parentName:"p"},"Microsoft Fabric")," and ",(0,o.kt)("strong",{parentName:"p"},"Power BI"),"."),(0,o.kt)("p",null,"Key elements of the solution include:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Infrastructure as code (IaC) for all infrastructure components (Terraform)."),(0,o.kt)("li",{parentName:"ul"},"Deployment pipelines to enable CI/CD and DataOps for the platform and all data workloads."),(0,o.kt)("li",{parentName:"ul"},"Sample ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/ingest_data_azure"},"data ingest pipelines")," that transfer data from a source into the landing (Bronze) data lake zone."),(0,o.kt)("li",{parentName:"ul"},"Sample ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/data_processing"},"data processing pipelines")," performing data transformations from Bronze to Silver and Silver to Gold layers.")),(0,o.kt)("p",null,"The solution utilises the ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/data_engineering/stacks_data_utilities"},"Stacks Data Python library"),", which offers a suite of utilities to support:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Data transformations using PySpark."),(0,o.kt)("li",{parentName:"ul"},"Frameworks for ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/data_quality_azure"},"data quality validations")," and ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/testing_data_azure"},"automated testing"),"."),(0,o.kt)("li",{parentName:"ul"},"The ",(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/datastacks"},"Datastacks CLI")," - a tool enabling developers to quickly generate new data workloads.")),(0,o.kt)("h3",{id:"high-level-architecture"},"High-level architecture"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"High-level architecture",src:t(2808).Z,width:"2559",height:"1435"})),(0,o.kt)("h3",{id:"infrastructure-deployed"},"Infrastructure deployed"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Resource Group"),(0,o.kt)("li",{parentName:"ul"},"Key Vault"),(0,o.kt)("li",{parentName:"ul"},"Azure Data Lake Storage Gen2"),(0,o.kt)("li",{parentName:"ul"},"Azure Blob Storage"),(0,o.kt)("li",{parentName:"ul"},"Azure Data Factory"),(0,o.kt)("li",{parentName:"ul"},"Log Analytics Workspace"),(0,o.kt)("li",{parentName:"ul"},"Databricks Workspace"),(0,o.kt)("li",{parentName:"ul"},"Azure SQL Database (optional, for testing the platform)")),(0,o.kt)("p",null,"The deployed platform can ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/data_engineering/data_engineering_intro_azure#fabric-lakehouse"},"integrate with Microsoft Fabric")," to provide a suite of analytics tools and capabilities."),(0,o.kt)("p",null,"The solution is designed to be deployed within a secure private network - for details see ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/architecture/infrastructure_data_azure"},"infrastructure and networking"),"."),(0,o.kt)("h3",{id:"data-engineering-workloads"},"Data Engineering workloads"),(0,o.kt)("p",null,"Example data engineering workloads are provided, based upon the Datastacks templates:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/ingest_data_azure"},"Ingest")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/data_processing"},"Bronze to Silver")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/data_processing"},"Silver to Gold"))),(0,o.kt)("p",null,"Each of the ingest and data processing workloads may optionally include ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/data_engineering/data_quality_azure"},"data quality checks"),"."))}f.isMDXComponent=!0},2808:function(e,a,t){a.Z=t.p+"assets/images/Stacks_Azure_Data_Platform-HLD-bd0d72d342d7cf2bf95c3c4384fe160d.png"},8821:function(e,a,t){a.Z=t.p+"assets/images/stacks-data-overview-a179ba5ce75d215026d7ea9eefcd0e1d.png"}}]);