"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[8519],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return m}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),u=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},k=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=u(a),k=r,m=d["".concat(l,".").concat(k)]||d[k]||p[k]||i;return a?n.createElement(m,o(o({ref:t},c),{},{components:a})):n.createElement(m,o({ref:t},c))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=k;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:r,o[1]=s;for(var u=2;u<i;u++)o[u]=a[u];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}k.displayName="MDXCreateElement"},2510:function(e,t,a){a.r(t),a.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return u},toc:function(){return d}});var n=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={id:"stacks_data_utilities",title:"Stacks Data Utilities",sidebar_label:"Stacks Data Utilities",hide_title:!1,hide_table_of_contents:!1,description:"Stacks Data utilities overview",keywords:["pyspark","spark","python","etl"]},l=void 0,u={unversionedId:"workloads/azure/data/data_engineering/stacks_data_utilities",id:"workloads/azure/data/data_engineering/stacks_data_utilities",title:"Stacks Data Utilities",description:"Stacks Data utilities overview",source:"@site/docs/workloads/azure/data/data_engineering/stacks_data_utilities.md",sourceDirName:"workloads/azure/data/data_engineering",slug:"/workloads/azure/data/data_engineering/stacks_data_utilities",permalink:"/docs/workloads/azure/data/data_engineering/stacks_data_utilities",draft:!1,tags:[],version:"current",frontMatter:{id:"stacks_data_utilities",title:"Stacks Data Utilities",sidebar_label:"Stacks Data Utilities",hide_title:!1,hide_table_of_contents:!1,description:"Stacks Data utilities overview",keywords:["pyspark","spark","python","etl"]},sidebar:"docs",previous:{title:"Data Engineering Overview",permalink:"/docs/workloads/azure/data/data_engineering/data_engineering_intro_azure"},next:{title:"Datastacks CLI",permalink:"/docs/workloads/azure/data/data_engineering/datastacks"}},c={},d=[{value:"Setup",id:"setup",level:2},{value:"Azure environment variables",id:"azure-environment-variables",level:2}],p={toc:d},k="wrapper";function m(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)(k,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://pypi.org/project/stacks-data/"},(0,i.kt)("strong",{parentName:"a"},"stacks-data"))," is a Python library, containing a suite of utilities to accelerate development within an Ensono Stacks Data Platform. It is an integral part of the platform, supporting common tasks such as generating new data engineering workloads and running Spark jobs. ",(0,i.kt)("strong",{parentName:"p"},"stacks-data")," consists of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/datastacks"},"Datastacks CLI")," - A command-line interface for data engineers, enabling interaction with Datastacks' various functions."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/datastacks#generating-data-workloads"},"Data workload generation")," - Generate new data workloads based upon common templates."),(0,i.kt)("li",{parentName:"ul"},"PySpark utilities - A suite of reusable utilities to simplify development of data pipelines using Apache Spark and Python."),(0,i.kt)("li",{parentName:"ul"},"Data quality utilities - Utilities to support the ",(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/data_quality_azure"},"data quality framework")," implemented in Stacks."),(0,i.kt)("li",{parentName:"ul"},"Azure utilities - Utilities to support common interactions with Azure resources from data workloads."),(0,i.kt)("li",{parentName:"ul"},"Behave utilities - Common scenarios and setup used by ",(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/data_engineering/testing_data_azure#end-to-end-tests"},"Behave end-to-end tests"),".")),(0,i.kt)("h2",{id:"setup"},"Setup"),(0,i.kt)("p",null,"The following setup steps will ensure your development environment is setup correctly and install ",(0,i.kt)("strong",{parentName:"p"},"stacks-data")," in your Python virtual environment:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Install the ",(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/getting_started/requirements_data_azure#local-development"},"local development requirements"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure"},"Setup your local development environment"),".")),(0,i.kt)("p",null,"Alternatively, you can directly install stacks-data from ",(0,i.kt)("a",{parentName:"p",href:"https://pypi.org/project/stacks-data/"},"PyPi"),", using:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install stacks-data\n")),(0,i.kt)("p",null,"For information on utilising ",(0,i.kt)("strong",{parentName:"p"},"stacks-data")," from within Databricks - see ",(0,i.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure#optional-pyspark-development-in-databricks"},"development in Databricks"),"."),(0,i.kt)("h2",{id:"azure-environment-variables"},"Azure environment variables"),(0,i.kt)("p",null,"To interact with Azure resources, the following additional environment variables are currently required:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"AZURE_TENANT_ID"),": Directory ID for Azure Active Directory application."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"AZURE_CLIENT_ID"),": Application ID for Azure Active Directory application."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"AZURE_CLIENT_SECRET"),": Service Principal Secret."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"ADLS_ACCOUNT"),": ADLS account name."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"BLOB_ACCOUNT"),": Blob Storage account name.")))}m.isMDXComponent=!0}}]);