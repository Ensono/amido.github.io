"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[6841],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return f}});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(a),m=i,f=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return a?n.createElement(f,r(r({ref:t},c),{},{components:a})):n.createElement(f,r({ref:t},c))}));function f(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:i,r[1]=l;for(var p=2;p<o;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},712:function(e,t,a){a.r(t),a.d(t,{contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return c}});var n=a(7462),i=a(3366),o=(a(7294),a(3905)),r=["components"],l={id:"pysparkle_data_quality",title:"PySparkle Data Quality",sidebar_label:"Data Quality",hide_title:!1,hide_table_of_contents:!1,description:"PySparkle Data Quality overview",keywords:["pysparkle","spark","pyspark","python","data quality"]},s=void 0,p={unversionedId:"workloads/common/data/pysparkle/pysparkle_data_quality",id:"workloads/common/data/pysparkle/pysparkle_data_quality",isDocsHomePage:!1,title:"PySparkle Data Quality",description:"PySparkle Data Quality overview",source:"@site/docs/workloads/common/data/pysparkle/pysparkle_data_quality.md",sourceDirName:"workloads/common/data/pysparkle",slug:"/workloads/common/data/pysparkle/pysparkle_data_quality",permalink:"/docs/workloads/common/data/pysparkle/pysparkle_data_quality",tags:[],version:"current",frontMatter:{id:"pysparkle_data_quality",title:"PySparkle Data Quality",sidebar_label:"Data Quality",hide_title:!1,hide_table_of_contents:!1,description:"PySparkle Data Quality overview",keywords:["pysparkle","spark","pyspark","python","data quality"]},sidebar:"docs",previous:{title:"Quickstart",permalink:"/docs/workloads/common/data/pysparkle/pysparkle_quickstart"},next:{title:"Development Quickstart",permalink:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure"}},c=[{value:"Usage",id:"usage",children:[],level:2},{value:"JSON Configuration File for Great Expectations",id:"json-configuration-file-for-great-expectations",children:[{value:"Example",id:"example",children:[],level:3},{value:"Using environment variables in configuration files",id:"using-environment-variables-in-configuration-files",children:[],level:3}],level:2}],u={toc:c},d="wrapper";function m(e){var t=e.components,a=(0,i.Z)(e,r);return(0,o.kt)(d,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"PySparkle performs data quality checks based on the user-provided configurations. At its core, it\nutilises the capabilities of the ",(0,o.kt)("a",{parentName:"p",href:"https://greatexpectations.io/"},"Great Expectations")," platform."),(0,o.kt)("h2",{id:"usage"},"Usage"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'pysparkle data-quality --help\npysparkle data-quality --config-path "data_quality/silver_dq.json"\n')),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"config-path")," is a Path to a JSON config inside an Azure Blob container. The container name\nfor storing configurations is ",(0,o.kt)("inlineCode",{parentName:"p"},"config")," and it is defined in the configuration set in the pysparkle\npackage."),(0,o.kt)("p",null,"Azure Blob storage account name is expected to be set in an environment variable as explained\nin the main README file."),(0,o.kt)("h2",{id:"json-configuration-file-for-great-expectations"},"JSON Configuration File for Great Expectations"),(0,o.kt)("p",null,"This section describes the structure of the JSON configuration file used in our system.\nThe configuration is defined using Python's Pydantic library for data validation."),(0,o.kt)("p",null,"Here is the description of the main elements:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"gx_directory_path"),": Path to the Great Expectations metadata store."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"dataset_name"),": Name of the dataset that is being processed."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"datasource_config"),": List of datasource configurations where each configuration contains the following fields:",(0,o.kt)("ol",{parentName:"li"},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"datasource_name"),": Name of the data asset, e.g., table or file name."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"datasource_type"),": Source system type that Spark can read from, e.g. table, parquet, csv, delta."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"data_location"),": Location of the given data asset. It can either be a path to the data file\nor a fully qualified table name, depending on the data source. Expectations for each scenario:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"File Path"),": If the data is stored in a file, like a Parquet file on ADLS, you should\nprovide the complete path to the file. Examples:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},'"abfss://raw@accountname.dfs.core.windows.net/myfolder/mysubfolder/myfile.parquet"'),","),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},'"abfss://raw@accountname.dfs.core.windows.net/myfolder/mysubfolder/*"'),","),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},'"abfss://silver@{ADLS_ACCOUNT}.dfs.core.windows.net/myfolder/mysubfolder/*"'),"."))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Table Name"),": For tables with metadata managed by a data catalog, you should provide\nthe database schema and the table name. For example, ",(0,o.kt)("inlineCode",{parentName:"li"},"staging.table_name"),"."))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"expectation_suite_name"),": Name of the expectation suite associated with this data source."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"validation_config"),": A list of validation configurations where each configuration contains the following fields:",(0,o.kt)("ol",{parentName:"li"},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"column_name"),": Name of the validated column."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"expectations"),": List of expectations where each expectation has the following fields:"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"expectation_type"),": Name of the Great Expectations expectation class to use."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"expectation_kwargs"),": The keyword arguments to pass to the expectation class.")))))),(0,o.kt)("h3",{id:"example"},"Example"),(0,o.kt)("p",null,"Here's a minimal example of a configuration file:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "gx_directory_path": "/dbfs/great_expectations/",\n    "dataset_name": "movies_dataset",\n    "datasource_config": [\n        {\n            "datasource_name": "movies_metadata",\n            "datasource_type": "table",\n            "data_location": "staging.movies_metadata",\n            "expectation_suite_name": "movies_metadata_suite",\n            "validation_config": [\n                {\n                    "column_name": "adult",\n                    "expectations": [\n                        {\n                            "expectation_type": "expect_column_values_to_not_be_null",\n                            "expectation_kwargs": {}\n                        },\n                        {\n                            "expectation_type": "expect_column_values_to_be_of_type",\n                            "expectation_kwargs": {"type_": "StringType"}\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}\n')),(0,o.kt)("h3",{id:"using-environment-variables-in-configuration-files"},"Using environment variables in configuration files"),(0,o.kt)("p",null,"It is possible to use environment variables in a configuration file for Data Quality.\nPlaceholders in the form of ",(0,o.kt)("inlineCode",{parentName:"p"},"{ENV_VAR_NAME}")," will be replaced with the corresponding environment\nvariable values. For example, you can pass the ADLS name using an environment variable:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "data_location": "abfss://raw@{ADLS_ACCOUNT}.dfs.core.windows.net/example_azuresql_1/SalesLT.Product/v1/*/*/*"\n}\n')))}m.isMDXComponent=!0}}]);