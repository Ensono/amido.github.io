"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[4738],{3619:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"workloads/azure/data/getting_started/requirements_data_azure","title":"Prerequisites","description":"Prerequisites for developing with Ensono Stacks Data Platform","source":"@site/docs/workloads/azure/data/getting_started/requirements_data_azure.md","sourceDirName":"workloads/azure/data/getting_started","slug":"/workloads/azure/data/getting_started/requirements_data_azure","permalink":"/docs/workloads/azure/data/getting_started/requirements_data_azure","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"requirements_data_azure","title":"Prerequisites","sidebar_label":"Prerequisites","hide_title":false,"hide_table_of_contents":false,"description":"Prerequisites for developing with Ensono Stacks Data Platform","keywords":["requirements","prerequisites"]},"sidebar":"docs","previous":{"title":"Getting Started","permalink":"/docs/workloads/azure/data/getting_started/"},"next":{"title":"1. Generate a data project","permalink":"/docs/workloads/azure/data/getting_started/generate_project"}}');var s=t(4848),i=t(8453);const o={id:"requirements_data_azure",title:"Prerequisites",sidebar_label:"Prerequisites",hide_title:!1,hide_table_of_contents:!1,description:"Prerequisites for developing with Ensono Stacks Data Platform",keywords:["requirements","prerequisites"]},a=void 0,d={},c=[{value:"Local development",id:"local-development",level:2},{value:"Git repository",id:"git-repository",level:2},{value:"Azure subscription",id:"azure-subscription",level:2},{value:"Terraform state storage",id:"terraform-state-storage",level:3},{value:"CI/CD - Azure DevOps",id:"cicd---azure-devops",level:2},{value:"Azure Pipelines variable groups",id:"azure-pipelines-variable-groups",level:3},{value:"Github PAT Token",id:"github-pat-token",level:3},{value:"Azure Pipelines Service Connections",id:"azure-pipelines-service-connections",level:3}];function l(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",section:"section",strong:"strong",sup:"sup",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components},{Details:t}=r;return t||function(e,r){throw new Error("Expected "+(r?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.h2,{id:"local-development",children:"Local development"}),"\n",(0,s.jsx)(r.p,{children:"The following tools are recommended for developing while using the Ensono Stacks data solution:"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Tool"}),(0,s.jsx)(r.th,{children:"Notes"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"https://www.python.org/downloads/",children:"Python 3.9 - 3.11"})}),(0,s.jsxs)(r.td,{children:["Use of Python 3.12+ is not currently supported. You may wish to use a utility such as ",(0,s.jsx)(r.a,{href:"https://pypi.org/project/pyenv/",children:"pyenv"})," to manage your local versions of Python."]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"https://python-poetry.org/docs/",children:"Poetry"})}),(0,s.jsx)(r.td,{children:"Used for Python dependency management in Stacks."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsxs)(r.td,{children:["(Windows users) a Linux distribution, e.g. ",(0,s.jsx)(r.a,{href:"https://docs.microsoft.com/en-us/windows/wsl/install",children:"WSL"})]}),(0,s.jsx)(r.td,{children:"A Unix-based environment is recommended for developing the solution (e.g. macOS, Linux, or WSL for Windows users)."})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"Java 8/11/17 runtime"}),(0,s.jsxs)(r.td,{children:["Optional: Java is required to develop and run tests using PySpark locally - see ",(0,s.jsx)(r.a,{href:"https://spark.apache.org/docs/latest/",children:"Spark documentation"}),"."]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/cli/azure/install-azure-cli",children:"Azure CLI"})}),(0,s.jsx)(r.td,{children:"Optional: Azure CLI allows you to interact with Azure resources locally, including running end-to-end tests."})]})]})]}),"\n",(0,s.jsxs)(r.p,{children:["See ",(0,s.jsx)(r.a,{href:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure",children:"development quickstart"})," for further details on getting start with developing the solution."]}),"\n",(0,s.jsx)(r.h2,{id:"git-repository",children:"Git repository"}),"\n",(0,s.jsxs)(r.p,{children:["A remote Git repository is required for storing and managing a data project's code. This can be in either ",(0,s.jsx)(r.strong,{children:"GitHub"})," or ",(0,s.jsx)(r.strong,{children:"Azure DevOps"}),". When scaffolding a new data project, you will need the HTTPS URL of the repo."]}),"\n",(0,s.jsxs)(r.p,{children:["While Ensono Stacks supports storing code in both GitHub and Azure DevOps, it does not currently support CI/CD pipelines using GitHub Actions. Requirements for Azure DevOps are detailed in the ",(0,s.jsx)(r.a,{href:"#cicd---azure-devops",children:"CI/CD - Azure DevOps"})," section below."]}),"\n",(0,s.jsxs)(r.p,{children:["The examples and quickstart documentation assume that ",(0,s.jsx)(r.code,{children:"main"})," is the primary branch in the repo."]}),"\n",(0,s.jsx)(r.h2,{id:"azure-subscription",children:"Azure subscription"}),"\n",(0,s.jsx)(r.p,{children:"In order to deploy an Ensono Stacks Data Platform into Azure, you will need:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"One or more Azure subscriptions \u2013 for deploying the solution into"}),"\n",(0,s.jsxs)(r.li,{children:["Azure service principal (Application) \u2013 must have ",(0,s.jsx)(r.code,{children:"Contributor"})," access to deploy and configure all required\nresources into the target subscription(s)"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"terraform-state-storage",children:"Terraform state storage"}),"\n",(0,s.jsxs)(r.p,{children:["Deployment of Azure resources in Ensono Stacks is done through Terraform. Within your Azure subscription, you must provision a ",(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/azure/storage/blobs/blob-containers-portal",children:"storage container"})," to hold ",(0,s.jsx)(r.a,{href:"https://developer.hashicorp.com/terraform/language/state",children:"Terraform state data"}),". Details regarding this storage are required when you first scaffold the project using the Ensono Stacks CLI. Therefore, once you have provisioned the storage container, make note of the following:"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"Storage account name"}),"\n",(0,s.jsx)(r.li,{children:"Resource group name"}),"\n",(0,s.jsx)(r.li,{children:"Container name"}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"cicd---azure-devops",children:"CI/CD - Azure DevOps"}),"\n",(0,s.jsxs)(r.p,{children:["CI/CD processes within the Ensono Stacks Data Platform are currently designed to be run in Azure DevOps Pipelines",(0,s.jsx)(r.sup,{children:(0,s.jsx)(r.a,{href:"#user-content-fn-1",id:"user-content-fnref-1","data-footnote-ref":!0,"aria-describedby":"footnote-label",children:"1"})}),". Therefore, it is a requirement to ",(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/azure/devops/organizations/projects/create-project?view=azure-devops&tabs=browser",children:"create a project in Azure DevOps"}),"."]}),"\n",(0,s.jsx)(r.h3,{id:"azure-pipelines-variable-groups",children:"Azure Pipelines variable groups"}),"\n",(0,s.jsxs)(r.p,{children:["Our blueprint solution expects the following ",(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&tabs=yaml",children:"variable groups"}),"\nto exist in your Azure DevOps project's Pipelines Library:"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:["amido-stacks-de-pipeline-",(0,s.jsx)(r.em,{children:"env"})]}),"\n",(0,s.jsxs)(r.li,{children:["amido-stacks-euw-de-",(0,s.jsx)(r.em,{children:"env"}),"-network"]}),"\n",(0,s.jsxs)(r.li,{children:["stacks-credentials-",(0,s.jsx)(r.em,{children:"env"}),"-kv"]}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:["Where ",(0,s.jsx)(r.em,{children:"env"})," can be either ",(0,s.jsx)(r.code,{children:"nonprod"})," or ",(0,s.jsx)(r.code,{children:"prod"}),"."]}),"\n",(0,s.jsx)(r.p,{children:"Please refer to the following lists to identify the necessary variables for your project.\nThe specifics regarding when each variable is required have also been provided. Generally,\nthe variables fall into one of two categories based on the time of requirement: 'Project Start',\ndenoting variables required at the very outset of the project, and 'After Core Infrastructure\nDeployment', referring to variables required after the fundamental infrastructure has been deployed."}),"\n",(0,s.jsx)(r.admonition,{title:"Networking variables",type:"note",children:(0,s.jsxs)(r.p,{children:["The variables under ",(0,s.jsx)(r.code,{children:"amido-stacks-euw-de-env-network"})," are only required if you want to provision the infrastructure within a private network."]})}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"amido-stacks-de-pipeline-env"}),(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Variable Name"}),(0,s.jsx)(r.th,{children:"When Needed"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"ADLS_DataLake_URL"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Azure Data Lake Storage Gen2 URL"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"blob_adls_storage"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Azure Data Lake Storage Gen2 name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"blob_configStorage"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Blob storage name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"Blob_ConfigStore_serviceEndpoint"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Blob service URL"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"databricksHost"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Databricks URL"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"databricksWorkspaceResourceId"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Databricks workspace resource id"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"datafactoryname"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Azure Data Factory name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"github_token"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"GitHub PAT token, see below for more details"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"integration_runtime_name"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Azure Data Factory integration runtime name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"KeyVault_baseURL"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Vault URI"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"keyvault_name"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Key Vault name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"location"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Azure region"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"resource_group"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Name of the resource group"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"sql_connection"}),(0,s.jsx)(r.td,{children:"After core infra"}),(0,s.jsx)(r.td,{children:"Connection string to Azure SQL database"})]})]})]})]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"amido-stacks-euw-de-env-network"}),(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Variable Name"}),(0,s.jsx)(r.th,{children:"When Needed"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"databricks_private_subnet_name"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Name of the private databricks subnet"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"databricks_public_subnet_name"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Name of the public databricks subnet"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"pe_resource_group_name"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Name of the resource group to provision private VNet to"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"pe_subnet_name"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Name of the subnet to provision private endpoints into"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"pe_subnet_prefix"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:'Subnet CIDR, e.g. ["10.3.1.0/24"]'})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"pe_vnet_name"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Private VNet name"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"private_subnet_prefix"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:'Subnet CIDR, e.g. ["10.3.4.0/24"]'})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"public_subnet_prefix"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:'Subnet CIDR, e.g. ["10.3.3.0/24"]'})]})]})]})]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"stacks-credentials-env-kv"}),(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Variable Name"}),(0,s.jsx)(r.th,{children:"When Needed"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"azure-client-id"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Application ID for Azure Active Directory application"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"azure-client-secret"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Service principal secret"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"azure-subscription-id"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Subscription ID"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"azure-tenant-id"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsx)(r.td,{children:"Directory ID for Azure Active Directory application"})]})]})]})]}),"\n",(0,s.jsx)(r.h3,{id:"github-pat-token",children:"Github PAT Token"}),"\n",(0,s.jsxs)(r.p,{children:["Within the pipelines we use an Azure DevOps task called UsePythonVersion@0 which allows us to install a specific version of Python onto the build agent. If the Python version doesn't exist on the build agent, it will download it from ",(0,s.jsx)(r.a,{href:"https://github.com/actions/python-versions",children:"Github Actions"})," however this requires a Github PAT Token otherwise you may hit by a GitHub anonymous download limit.\nYou can create a token by following this ",(0,s.jsx)(r.a,{href:"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens",children:"guide"}),".\nYou do not require any permissions on this token because GitHub only needs to read your public profile."]}),"\n",(0,s.jsx)(r.h3,{id:"azure-pipelines-service-connections",children:"Azure Pipelines Service Connections"}),"\n",(0,s.jsx)(r.p,{children:"Service Connections are used in Azure DevOps Pipelines to connect to external services, like Azure and GitHub.\nYou must create the following Service Connections:"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Name"}),(0,s.jsx)(r.th,{children:"When Needed"}),(0,s.jsx)(r.th,{children:"Description"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"Stacks.Pipeline.Builds"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsxs)(r.td,{children:["The Service Connection to Azure. The service principal or managed identity that is used to create the connection must have contributor access to the Azure Subscription. See ",(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/azure/devops/pipelines/library/connect-to-azure?view=azure-devops",children:"Microsoft documentation"})," for more information."]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:"GitHubReleases"}),(0,s.jsx)(r.td,{children:"Project start"}),(0,s.jsxs)(r.td,{children:["The Service Connection to Github for releases. The access token that is used to create the connection must have read/write access to the GitHub repository. See ",(0,s.jsx)(r.a,{href:"https://learn.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=azure-devops#github-service-connection",children:"Microsoft documentation"})," for more information."]})]})]})]}),"\n","\n",(0,s.jsxs)(r.section,{"data-footnotes":!0,className:"footnotes",children:[(0,s.jsx)(r.h2,{className:"sr-only",id:"footnote-label",children:"Footnotes"}),"\n",(0,s.jsxs)(r.ol,{children:["\n",(0,s.jsxs)(r.li,{id:"user-content-fn-1",children:["\n",(0,s.jsxs)(r.p,{children:["More general information on ",(0,s.jsx)(r.a,{href:"/docs/infrastructure/azure/pipelines/azure_devops",children:"using Azure Pipelines in Stacks"})," is also available. ",(0,s.jsx)(r.a,{href:"#user-content-fnref-1","data-footnote-backref":"","aria-label":"Back to reference 1",className:"data-footnote-backref",children:"\u21a9"})]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},8453:(e,r,t)=>{t.d(r,{R:()=>o,x:()=>a});var n=t(6540);const s={},i=n.createContext(s);function o(e){const r=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(i.Provider,{value:r},e.children)}}}]);