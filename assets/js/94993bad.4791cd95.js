"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[276],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return k}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),m=a,k=p["".concat(s,".").concat(m)]||p[m]||d[m]||o;return n?r.createElement(k,i(i({ref:t},c),{},{components:n})):r.createElement(k,i({ref:t},c))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:a,i[1]=l;for(var u=2;u<o;u++)i[u]=n[u];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2366:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return s},default:function(){return m},frontMatter:function(){return l},metadata:function(){return u},toc:function(){return c}});var r=n(7462),a=n(3366),o=(n(7294),n(3905)),i=["components"],l={id:"dev_quickstart_data_azure",title:"Local Development Quickstart",sidebar_label:"2. Local Development Quickstart",hide_title:!1,hide_table_of_contents:!1,description:"Quickstart for local development",keywords:["quickstart","development"]},s=void 0,u={unversionedId:"workloads/azure/data/getting_started/dev_quickstart_data_azure",id:"workloads/azure/data/getting_started/dev_quickstart_data_azure",isDocsHomePage:!1,title:"Local Development Quickstart",description:"Quickstart for local development",source:"@site/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure.md",sourceDirName:"workloads/azure/data/getting_started",slug:"/workloads/azure/data/getting_started/dev_quickstart_data_azure",permalink:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure",tags:[],version:"current",frontMatter:{id:"dev_quickstart_data_azure",title:"Local Development Quickstart",sidebar_label:"2. Local Development Quickstart",hide_title:!1,hide_table_of_contents:!1,description:"Quickstart for local development",keywords:["quickstart","development"]},sidebar:"docs",previous:{title:"1. Infrastructure Deployment",permalink:"/docs/workloads/azure/data/getting_started/core_data_platform_deployment_azure"},next:{title:"3. Shared Resources Deployment",permalink:"/docs/workloads/azure/data/getting_started/shared_resources_deployment_azure"}},c=[{value:"Environment setup",id:"environment-setup",children:[{value:"(Optional) Azure connection",id:"optional-azure-connection",children:[],level:3}],level:2},{value:"Running unit tests",id:"running-unit-tests",children:[],level:2},{value:"Running end-to-end tests",id:"running-end-to-end-tests",children:[],level:2},{value:"(Optional) PySpark development in Databricks",id:"optional-pyspark-development-in-databricks",children:[],level:2},{value:"Troubleshooting",id:"troubleshooting",children:[],level:2},{value:"Next steps",id:"next-steps",children:[],level:2}],p={toc:c},d="wrapper";function m(e){var t=e.components,n=(0,a.Z)(e,i);return(0,o.kt)(d,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"This section covers the steps required to start developing a Stacks Azure Data Platform from your machine:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},'Make sure you have installed the applications from the "Local development" section listed in\n',(0,o.kt)("a",{parentName:"li",href:"/docs/workloads/azure/data/requirements_data_azure"},"Requirements"),"."),(0,o.kt)("li",{parentName:"ol"},"Ensure that Poetry is added to your ",(0,o.kt)("inlineCode",{parentName:"li"},"$PATH"),".")),(0,o.kt)("h2",{id:"environment-setup"},"Environment setup"),(0,o.kt)("p",null,"A Makefile has been created to assist with setting up the development environment. Run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"make setup_dev_environment\n")),(0,o.kt)("h3",{id:"optional-azure-connection"},"(Optional) Azure connection"),(0,o.kt)("p",null,"In order to interact with Azure resources when developing, including running end-to-end tests, you must:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/cli/azure/install-azure-cli"},"Install the Azure CLI")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli"},"Sign in to the Azure CLI")),(0,o.kt)("li",{parentName:"ol"},"Set the following environment variables:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"AZURE_SUBSCRIPTION_ID")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"AZURE_RESOURCE_GROUP_NAME")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"AZURE_DATA_FACTORY_NAME")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"AZURE_REGION_NAME")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"AZURE_STORAGE_ACCOUNT_NAME"))))),(0,o.kt)("h2",{id:"running-unit-tests"},"Running unit tests"),(0,o.kt)("p",null,"In order to run unit tests, run the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"make test\n")),(0,o.kt)("h2",{id:"running-end-to-end-tests"},"Running end-to-end tests"),(0,o.kt)("p",null,"Running the end-to-end tests will involve executing Data Factory pipelines in Azure. Ensure you have setup the ",(0,o.kt)("a",{parentName:"p",href:"#optional-azure-connection"},"Azure connection")," and run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"make test_e2e\n")),(0,o.kt)("h2",{id:"optional-pyspark-development-in-databricks"},"(Optional) PySpark development in Databricks"),(0,o.kt)("p",null,"When developing with PySpark, you may wish to either:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Run scripts locally using a local Spark installation, or"),(0,o.kt)("li",{parentName:"ul"},"Run scripts on a Databricks cluster, through ",(0,o.kt)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/azure/databricks/repos/"},"Databricks Repos"),".")),(0,o.kt)("p",null,"To run scripts within a Databricks cluster, you will need to:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Install the Datastacks whl file on the cluster, either from:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"The latest deployed version in ",(0,o.kt)("inlineCode",{parentName:"li"},"dbfs:/FileStore/jars/datastacks-latest-py3-none-any.whl"),", or"),(0,o.kt)("li",{parentName:"ul"},"Create a new whl file with the ",(0,o.kt)("inlineCode",{parentName:"li"},"poetry build")," command."))),(0,o.kt)("li",{parentName:"ul"},"Add Spark environment variables, as per the Data Factory linked service (see ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/Ensono/stacks-azure-data/blob/main/de_workloads/shared_resources/data_factory/adf_linked_services.tf"},"adf_linked_services.tf"),")."),(0,o.kt)("li",{parentName:"ul"},"Ensure the user has appropriate permissions for Azure resources required.")),(0,o.kt)("h2",{id:"troubleshooting"},"Troubleshooting"),(0,o.kt)("p",null,"\u2139\ufe0f If you encounter PATH-related issues with Poetry when running the tests, we recommend installing Poetry using\n",(0,o.kt)("a",{parentName:"p",href:"https://python-poetry.org/docs/#installing-with-pipx"},"pipx")," rather than the official installer."),(0,o.kt)("p",null,"\u2139\ufe0f Running end-to-end tests from your local machine may require additional permissions in Azure. If the tests fail whilst clearing up directories, ensure that you have ",(0,o.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#storage-blob-data-contributor"},"Storage Blob Data Contributor")," access applied to your Azure Active Directory subscription. You may also be required to configure the ",(0,o.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/storage/common/storage-network-security"},"firewall rules")," for the storage account to whitelist your IP address."),(0,o.kt)("h2",{id:"next-steps"},"Next steps"),(0,o.kt)("p",null,"Once you setup your local development environment, you can continue with the Getting Started tutorial by ",(0,o.kt)("a",{parentName:"p",href:"/docs/workloads/azure/data/getting_started/shared_resources_deployment_azure"},"deploying the Shared Resources"),"."))}m.isMDXComponent=!0}}]);