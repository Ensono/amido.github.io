"use strict";(self.webpackChunkstacks=self.webpackChunkstacks||[]).push([[3199],{8546:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>n,metadata:()=>i,toc:()=>l});var r=a(4848),s=a(8453);const n={id:"getting_started",title:"Getting Started",sidebar_label:"Getting Started",hide_title:!1,hide_table_of_contents:!1,description:"Getting Started with Ensono Stacks Data",keywords:["ensono stacks","data","azure"]},o=void 0,i={id:"workloads/azure/data/getting_started/getting_started",title:"Getting Started",description:"Getting Started with Ensono Stacks Data",source:"@site/docs/workloads/azure/data/getting_started/getting_started.md",sourceDirName:"workloads/azure/data/getting_started",slug:"/workloads/azure/data/getting_started/",permalink:"/docs/workloads/azure/data/getting_started/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"getting_started",title:"Getting Started",sidebar_label:"Getting Started",hide_title:!1,hide_table_of_contents:!1,description:"Getting Started with Ensono Stacks Data",keywords:["ensono stacks","data","azure"]},sidebar:"docs",previous:{title:"Testing",permalink:"/docs/workloads/azure/data/data_engineering/testing_data_azure"},next:{title:"Prerequisites",permalink:"/docs/workloads/azure/data/getting_started/requirements_data_azure"}},d={},l=[{value:"Steps",id:"steps",level:2}];function c(e){const t={a:"a",em:"em",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:["This ",(0,r.jsx)(t.em,{children:"Getting Started"})," section provides the steps needed to get up and running with an Ensono Stacks Data Platform. It follows the ",(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/architecture/architecture_data_azure",children:"Ensono Stacks Data deployment workflow"}),"."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Ensono Stacks Data workflow - high-level",src:a(6491).A+"",width:"2808",height:"811"})}),"\n",(0,r.jsxs)(t.p,{children:["A more ",(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/architecture/architecture_data_azure#detailed-workflow",children:"detailed workflow diagram"})," is also available."]}),"\n",(0,r.jsx)(t.h2,{id:"steps",children:"Steps"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/requirements_data_azure",children:"Prerequisites"})," - Ensure you have the necessary tools and resources to get started."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/generate_project",children:"Generate a Data Project"})," - Generate a new data project."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/core_data_platform_deployment_azure",children:"Infrastructure Deployment"})," - Deploy the data platform infrastructure into your cloud environment."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/dev_quickstart_data_azure",children:"Local Development Quickstart"})," - Once your project has been generated, setup your local environment to start developing."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/shared_resources_deployment_azure",children:"Shared Resources Deployment"})," - Deploy common resources to be shared across data pipelines."]}),"\n",(0,r.jsxs)(t.li,{children:["(Optional) ",(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/example_data_source",children:"Example Data Source"})," - To assist with the 'Getting Started' steps, you may wish to setup the Example Data Source."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/ingest_pipeline_deployment_azure",children:"Data Ingest Pipeline Deployment"})," - Generate and deploy a data ingest pipeline using the Datastacks CLI."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/processing_pipeline_deployment_azure",children:"Data Processing Pipeline Deployment"})," - Generate and deploy a data processing pipeline using the Datastacks CLI."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/docs/workloads/azure/data/getting_started/fabric_deployment_guide",children:"Fabric Lakehouse Deployment"})," - Steps to implement a Microsoft Fabric Lakehouse over the data platform."]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},6491:(e,t,a)=>{a.d(t,{A:()=>r});const r=a.p+"assets/images/stacks-data-workflow-high-level-8ab0afefb59ce7743263afc2c7fff2ec.png"},8453:(e,t,a)=>{a.d(t,{R:()=>o,x:()=>i});var r=a(6540);const s={},n=r.createContext(s);function o(e){const t=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(n.Provider,{value:t},e.children)}}}]);